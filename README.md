# Welcome 

Welcome to the Galvanize Data Science Immersive Program!  On this page you'll find information you about the program as a whole as well as links to daily readings and assignments.  You'll be working with this page everyday - please bookmark it in your web browser. 

# Weekly overview
The Data Science Immersive (DSI) has 8 instructional weeks, 3 capstone weeks, and the final showcase week.  Most instructional weeks begin with a 1 hour assessment on Monday and end with a group case study on Friday. 

The capstone weeks are reserved for your capstone projects (see below).  You will scrum with your peers during this time, participate in mock job interiews, and at the end of the week present your project to either your peers and instructors (capstones 1 & 2), or the data science community in the capstone showcase (capstone 3).

The final week is reserved for finishing your capstone, completing Career Services deliverables, presenting at the capstone showcase, and graduating.

To jump to a week of interest, click on the link.  

| Week | Date | Topic |
| --- | --- | --- |
| 1 | 05/06/19| [Programming](#week-1-programming-for-data-science) |
| 2 | 05/13/19 |  [Big Data](#week-2-big-data) |
| 3 | 05/20/19 | [Statistical Inference](#week-3-statistical-inference) |
| 4 | 05/27/19 | [Capstone 1](#week-4-unit-1-capstone) |
| 5 | 06/03/19 | [Regression](#week-5-supervised-learning-and-regression) |
| - | 06/10/19 | Break Week |
| 6 | 06/17/19 | [Supervised Learning](#week-6-nonlinear-supervised-learning) |
| 7 | 06/24/19 | [Unsupervised Learning](#week-7-nlp-and-unsupervised-learning)|
| 8 | 07/01/19 | [Capstone 2](#week-8-unit-2-capstone) |
| 9 | 07/08/19 | [Advanced Topics 1](#week-9-advanced-topics-1) |
| 10 | 07/15/19 | [Advanced Topics 2](#week-10-advanced-topics-2) |
| 11 | 07/22/19 | [Capstone 3](#week-11-unit-3-capstone) |
| 12 | 07/29/19 | [Showcase](#week-12-showcase) |

## Other important links
* [Solutions repo](https://github.com/GalvanizeDataScience/solutions-g90)  Solutions for the daily assignments, weekly reviews, and assessments will be added to this repository.  If a solution is missing, please bug an instructor!
* [Weekly feedback](https://forms.gle/QaHo9NyxC2ZYFi2u8)  Every Friday you'll be given some time to reflect on the week and be given a chance to let us know how you're doing.  Then let us know how well you think we taught the material.  We'll use your contstructive criticism to adapt as the course proceeds.
* [Past student projects](https://github.com/gSchool/dsi-project-proposals/blob/master/past_student_projects.md)  Whether you're looking for capstone ideas or resources to help you with your current capstone, take a look here.  The instructor voted most exemplary/helpful ones are marked with an astericks.


## Capstone Project
Capstone projects allow you to put in to practice some of the knowledge you are gaining in the program on projects of your choosing.  They help build your Github portfolio, and give you specific skills to talk about during job interviews.You will submit capstone proposals to the instructors for approval before the capstone weeks begin.  Very often capstone 3 builds on work done on capstone 2, and sometimes even capstone 1.


# Daily Outline
In the weekly tables below, each row represents a day.  Each row information and links on:

* __Day:__ Day of the Week
* __Readings__ Readings for the day (to be completed the night before).
* __Repos:__ The day's exercises. 
* __Lead:__ The instructor who is the point person for the day.
* __Slides:__ The day's lecture notes and slides.


### Week 1: Programming for Data Science
| Day  | Readings                                 | Repos                                          |  Lead   |        Slides       |  
|:----:|:----------------------------------------:|:----------------------------------------------:|:-------:|:-------------------:|    
| Mon. |[AWS credit][r-aws]<br>[Unix][r-unix]     |Assessment 0<br>[git][git]<br>[Unix][unix]      |  Frank  |[1][l-git]           |
| Tue. |[Code style][r-python]<br>[Classes][r-oop]|[Python Intro.][python]<br>[OOP][oop]           |  Frank  |[1][l-p]<br>[2][l-oo]|
| Wed. |Think Python                              |[Pandas][c1.2.1] <br/> [Matplotlib][c1.2.2]     |    -    | [b][-] |
| Thu. |n/a                                       | [Linear Algebra][c1.4.1]<br/>[Numpy][c1.4.2]   |  -      | [][ ] |
| Fri. |n/a                                       | [Mongo DB][c1.5.1]<br/>[Web Scraping][c1.5.2]  |  -      | [slides][-] |

--

### Week 2: Big Data
| Day | Topic | Lead Instructor | Slides |
|:--:|:--|:--:|:--:|
| Monday | [Assessment 1][-]<br/>[Algorithmic Complexity][c2.1.1]<br/>[Data Structures][c2.1.2] |  - <br/> -  | [Slides][-] |
| Tuesday | [Docker][c2.2.1]<br/>[AWS][c2.2.2]  |  - | [slides][-]  |
| Wednesday | [SQL][-]<br>[Python SQL][-] |  -  | [slides][-]] |
| Thursday |  [Spark RDDs][c2.4.1]<br/>[Spark SQL][c2.4.2] |  -  | [slides][-] |
| Friday |  [Spark EDA Case Study][c2.5.1] |  -   | [slides][150.2] |

--

### Week 3: Statistical Inference
| Day | Topic | Lead Instructor | Slides |
|:--:|:--|:--:|:--:|
| Monday | [Assessment][-]<br/>[Probability][-]<br/>[Binomial Tests][-] |  -  | [slides][-] |
| Tuesday |  [Sampling Distributions][c3.2.1]<br/>[Law of Large Numbers][c3.2.2] |  -  | [slides][-] |
| Wednesday |  [Central Limit Theorem][c3.3.1]<br/>[Maximum Likelihood Estimation][c3.3.2] |  -  | [slides][-] |
| Thursday |  [Hypothesis Testing][c3.4.1]<br/>[Power Calculation][c3.4.2] |  -  | [slides][-] |
| Friday | [Stats Case Study][-] |  -   | - |

--

### Week 4: Unit 1 Capstone 
| Day  | Topic | Lead Instructor | Slides |
|:--:|:--|:--:|:--:|
| Monday |   [Data Products][132.0] |  -   | [slides][-] |
| Tuesday |  Discuss and kickoff capstone 1 |  -  | - |
| Wednesday |  Work! | - | - |
| Thursday |  MORE WORK!!!! | - | - |
| Friday | Capstone Presentations PM | - | - |

--

### Week 5: Supervised Learning and Regression
| Day | Topic | Lead Instructor | Slides |
|:--:|:--|:--:|:--:|
| Monday | [Assessment][-]<br/>[KNN][c5.1.1]<br/>[Cross Validation][c5.1.2] | - | [slides][-] |
| Tuesday |  [Predictive Linear Regression][c5.2.1] |  -   | [slides][-] |
| Wednesday |  [Regularized Regression][c5.3.1]<br/>[Inferential Regression][c5.3.2] |  -  | [slides][-] |
| Thursday | [Logistic Regression][c5.4.1]<br/>[Classification Measures of Effectiveness][c5.4.2] |  -  | [slides][-] |
| Friday | [Regression Case Study][c5.5.1] |  -  | [slides][-] |

--
### Solo Week
Your priorities this week:
<ul>
<li>Study any material from the previous weeks.</li>
<li>Collect data for upcoming capstones</li>
<li>Recharge for the 2nd half of the course</li>
</ul>

--

### Week 6: Nonlinear Supervised Learning
| Day | Topic | Lead Instructor | Slides |
|:--:|:--|:--:|:--:|
| Monday | [Assessment][-]<br/>[Search Trees][c6.1.1]<br/>[Decision Trees][c6.1.2] | - | [slides][-] |
| Tuesday |  [Random Forests][c6.2.1] |  -   | [slides][-] |
| Wednesday |  [Gradient Boosted Regressors][c6.3.1]<br/>[Gradient Boosted Classifiers][c6.3.2] |  -  | [slides][-] |
| Thursday | [Gradient Decent][c6.4.1]<br/>[Basic Neural Networks][c6.4.2] |  -  | [slides][-] |
| Friday | [Supervised Learning Case Study][c6.5.1]  |  -  | [slides][-] |

--

### Week 7: NLP and Unsupervised Learning
| Day | Topic | Lead Instructor | Slides |
|:--:|:--|:--:|:--:|
| Monday | [Assessment][-]<br/>[NLP Intro][-]<br/>[Text Classification][-] | - | [slides][-] |
| Tuesday |  [PCA][-]<br/>[SVD][-] |  -   | [slides][-] |
| Wednesday |  [Clustering][-]<br/>[NMF][-] |  -  | [slides][-] |
| Thursday | [Graph Distance][-]<br/>[Graph Communities][-] |  -  | [slides][-] |
| Friday | [NLP Case Study][-] |  -  | [slides][-] |

--

### Week 8: Unit 2 Capstone 
| Day | Topic | Lead Instructor | Slides |
|:--:|:--|:--:|:--:|
| Monday | Discuss and kickoff capstone 2 | - | [slides][-] |
| Tuesday |  Work. |  -  | - |
| Wednesday |  Work! | - | - |
| Thursday |  MORE WORK!!!! | - | - |
| Friday | Capstone Presentations PM | - | - |

--

### Week 9: Advanced Topics 1
| Day | Topic | Lead Instructor | Slides |
|:--:|:--|:--:|:--:|
| Monday | [Assessment][-]<br/>[Bayesian Inference][-]<br/>[Bayesian Coin Flipping][-] | - | [slides][-] |
| Tuesday |  [Reinforcement Learning][-]<br/>[Multi-Armed Bandit][-] |  -   | [slides][-] |
| Wednesday |  [Similarity Based Recommenders][-]<br/>[Content Based Recommenders][-] |  -  | [slides][-] |
| Thursday | [Implicit Recommenders][-] |  -  | [slides][-] |
| Friday | [Recommender Case Study][-]  |  -  | [slides][-] |

--

### Week 10: Advanced Topics 2
| Day | Topic | Lead Instructor | Slides |
|:--:|:--|:--:|:--:|
| Monday | [Assessment][-]<br/>[Image Analysis][-]<br/>[CNNs][-] | - | [slides][-] |
| Tuesday |  [Sequence Analysis][-]<br/>[RNNs][-] |  -   | [slides][-] |
| Wednesday |  [Autoencoding][-]<br/>[Transfer Learning][-] |  -  | [slides][-] |
| Thursday | [Fraud Case Study (day 1)][-] |  -  | [slides][-] |
| Friday | [Fraud Case Study (day 2)][-] |  -  | [slides][-] |

--

### Week 11: Unit 3 Capstone
Kickoff your unit 3 capstone projects.  You will have daily sprint checkins.  No presentations this week, as you'll have a demo evening next week.

--

### Week 12: Showcase
| Day | Topic | Lead Instructor | Slides |
|:--:|:--|:--:|:--:|
| Monday |  | - | [slides][-] |
| Tuesday |   |  -   | [slides][-] |
| Wednesday |   |  -  | [slides][-] |
| Thursday | PM - Demo evening |  -  | [slides][-] |
| Friday | PM - Graduation |  -  | [slides][-] |

--

## Textbooks
We will focus on a few canonical texts for the class and readings will be assigned from them. If they are not in a physical form in our library, they are located in digital form on the Time Capsule or the Internet.
* [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Sixth%20Printing.pdf): The book we use for the majority of machine learning readings.
* [Machine Learning In Action](https://drive.google.com/file/d/0B1cm3fV8cnJwcUNWWnFaRWgwTDA/view?usp=sharing): 

### Supplementary
* [Doing Data Science](http://www.amazon.com/Doing-Data-Science-Straight-Frontline/dp/1449358659): One of the best treatments of the field with plenty of case studies.
* [Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do): Some of the `pandas` methods have changed (always reference `pandas` [online documentation](http://pandas.pydata.org/)) but a solid book on data analysis in Python.
* [Practical Data Science with R](http://www.manning.com/zumel/): through we will not use R, this is a stellar book and we will use it for its content/theory

## Getting Help
* [Data Science Stack Exchange](http://datascience.stackexchange.com/)
* [Stats Stack Exchange](http://stats.stackexchange.com/)
* [MetaOptimize: ML and Datascience forum](http://metaoptimize.com/qa)

## References

### Machine Learning
* [Machine Learning in Action](http://www.manning.com/pharrington/)
* [Programming Collective Intelligence](http://www.amazon.com/Programming-Collective-Intelligence-Building-Applications/dp/0596529325)
* [Machine Learning for Hackers](http://shop.oreilly.com/product/0636920018483.do)
* [An Introduction to Machine Learning](http://alex.smola.org/drafts/thebook.pdf)

### Statistics
* [Probabilistic Programming and Bayesian Methods for Hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)
* [Think Stats](http://www.greenteapress.com/thinkstats/)
* [Think Bayes](http://www.greenteapress.com/thinkbayes/)
* [All of Statistics](http://www.stat.cmu.edu/~larry/all-of-statistics/)
* [Mostly Harmless Econometrics](http://www.amazon.com/Mostly-Harmless-Econometrics-Empiricists-Companion/dp/0691120358)

### Computer Science/Programming
* [Think Python](http://www.greenteapress.com/thinkpython/thinkpython.html)
* [Algorithms (Papadimitriou)](http://www.cs.berkeley.edu/~vazirani/algorithms)
* [Think Complexity: Analysis of Algorithms](http://www.greenteapress.com/compmod/html/thinkcomplexity004.html)


### Numpy
* [Official Numpy Tutorial](http://wiki.scipy.org/Tentative_NumPy_Tutorial)
* [scipy Lectures](https://scipy-lectures.github.io/intro/numpy/index.html)
* [Crash Course in Python for Scientist](http://nbviewer.ipython.org/gist/rpmuller/5920182)
* [Scientific Python Lectures](http://nbviewer.ipython.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-2-Numpy.ipynb)
* [Numpy Broadcasting](http://wiki.scipy.org/EricsBroadcastingDoc)
* [Python Bootcamp Lectures](http://nbviewer.ipython.org/github/profjsb/python-bootcamp/blob/master/Lectures/05_NumpyMatplotlib/IntroNumPy.ipynb)

### SQL
* [http://sqlfiddle.com/](http://sqlfiddle.com/)
* [http://use-the-index-luke.com/](http://use-the-index-luke.com/)
* [http://missqlcommand.com/](http://missqlcommand.com/)
* [http://sql.learncodethehardway.org/book/](http://sql.learncodethehardway.org/book/)
* [SQL School](http://sqlschool.modeanalytics.com/)

### Scipy
* [scipy Lectures](https://scipy-lectures.github.io)

### scikit-learn
* [Introduction to Machine Learning with sklearn](http://researchcomputing.github.io/meetup_spring_2014/python/sklearn.html)
* [scikit-learn workshop](https://github.com/jakevdp/sklearn_pycon2014)
* [Machine Learning Tutorial](https://github.com/amueller/tutorial_ml_gkbionics)
* [Introduction to scikit-learn](http://nbviewer.ipython.org/github/tdhopper/Research-Triangle-Analysts--Intro-to-scikit-learn/blob/master/Intro%20to%20Scikit-Learn.ipynb)
* [Data analysis with scikit-learn](http://sebastianraschka.com/Articles/2014_scikit_dataprocessing.html)
* [Advanced Machine Learning with scikit-learn](https://us.pycon.org/2013/community/tutorials/23/)

### Extra
* [University of Colorado Computational Science workshops](http://researchcomputing.github.io/meetup_spring_2014/)
* [Networkx tutorial](http://snap.stanford.edu/class/cs224w-2012/nx_tutorial.pdf)

<!-- ************************** References **************************************** -->
<!-- References have been reorganized into several sections.  Please add links in accor - ce with the name and numbering schema-->

<!-- Lecture Repos -->
<!-- Week 1 -->

<!-- Content Repos (sprints and assessments) -->
<!-- Week 1 -->
[c1.1.1]: https://github.com/GalvanizeDataScience/unix
[c1.2.1]: https://github.com/GalvanizeDataScience/pandas
[c1.2.2]: https://github.com/GalvanizeDataScience/matplotlib
[c1.3.1]: https://github.com/GalvanizeDataScience/oop
[c1.4.1]: https://github.com/GalvanizeDataScience/linear-algebra
[c1.4.2]: https://github.com/GalvanizeDataScience/numpy
[c1.5.1]: https://github.com/GalvanizeDataScience/mongo-db
[c1.5.2]: https://github.com/GalvanizeDataScience/web-scraping

<!-- Week 2 -->
[c2.1.1]: https://github.com/GalvanizeDataScience/algorithmic-complexity
[c2.1.2]: https://github.com/GalvanizeDataScience/data-structures
[c2.2.1]: https://github.com/GalvanizeDataScience/docker
[c2.2.2]: https://github.com/GalvanizeDataScience/aws
[c2.4.1]: https://github.com/GalvanizeDataScience/spark-rdds
[c2.4.2]: https://github.com/GalvanizeDataScience/spark-dfs
[c2.5.1]: https://github.com/GalvanizeDataScience/Spark-Case-Study

<!-- Week 3 -->
[c3.2.1]: https://github.com/GalvanizeDataScience/sampling-distributions
[c3.2.2]: https://github.com/GalvanizeDataScience/law-of-large-numbers
[c3.3.1]: https://github.com/GalvanizeDataScience/central-limit
[c3.3.2]: https://github.com/GalvanizeDataScience/maximum-likelihood
[c3.4.1]: https://github.com/GalvanizeDataScience/hypothesis-testing
[c3.4.2]: https://github.com/GalvanizeDataScience/statistical-power

<!-- Week 4 -->


<!-- Week 5 -->
[c5.1.1]: https://github.com/GalvanizeDataScience/knn
[c5.1.2]: https://github.com/GalvanizeDataScience/cross-validation
[c5.2.1]: https://github.com/GalvanizeDataScience/predictive-linear-regression
[c5.3.1]: https://github.com/GalvanizeDataScience/regularized-regression
[c5.3.2]: https://github.com/GalvanizeDataScience/inferential-regression
[c5.4.1]: https://github.com/GalvanizeDataScience/logistic-regression
[c5.4.2]: https://github.com/GalvanizeDataScience/decision-rules
[c5.5.1]: https://github.com/GalvanizeDataScience/regression-case-study

<!-- Week 6-->
[c6.1.1]: https://github.com/GalvanizeDataScience/search-trees
[c6.1.2]: https://github.com/GalvanizeDataScience/decision-trees
[c6.2.1]: https://github.com/GalvanizeDataScience/random-forests
[c6.3.1]: https://github.com/GalvanizeDataScience/gradient-boosted-regression
[c6.3.2]: https://github.com/GalvanizeDataScience/gradient-boosted-classification
[c6.4.1]: https://github.com/GalvanizeDataScience/gradient-descent
[c6.4.2]: https://github.com/GalvanizeDataScience/perceptrons
[c6.5.1]: https://github.com/GalvanizeDataScience/supervised-learning-case-study/


<!-- Readings -->
<!-- Week 1 -->
[r1.1.1]: notes/workflow.md
[r1.1.2]: notes/pairing.md

<!-- Denver -->
<!-- Week 1 -->
[git]: https://github.com/gSchool/dsd-git-intro
[unix]: https://github.com/gSchool/dsd-unix
[r-aws]: notes/setup_aws.md
[r-unix]: https://en.wikipedia.org/wiki/Unix_philosophy 
[l-git]: https://github.com/gSchool/DSI_Lectures/tree/master/intro-git
[r-python]: https://docs.python-guide.org/writing/style/#general-concepts 
[r-oop]: http://www.greenteapress.com/thinkpython/html/thinkpython016.html
[python]: https://github.com/gSchool/dsd-python/
[oop]: https://github.com/gSchool/dsi-oop
[l-p]: https://github.com/gschool/DSI_Lectures/tree/master/python-intro
[l-oo]: https://github.com/gschool/DSI_Lectures/tree/master/OOP 

